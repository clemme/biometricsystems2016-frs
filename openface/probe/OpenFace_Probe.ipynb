{
 "metadata": {
  "name": "",
  "signature": "sha256:deb1226bb5079504b5d8fb4f5e250e8109fbdb0cdc271d085067762b27deda93"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import openface\n",
      "import os\n",
      "import argparse\n",
      "import itertools\n",
      "import cv2\n",
      "import numpy as np\n",
      "from PIL import Image\n",
      "import pandas as pd\n",
      "import csv\n",
      "import ast\n",
      "from xml.dom import minidom\n",
      "from datetime import datetime\n",
      "\n",
      "%matplotlib inline\n",
      "\n",
      "process = \"probe\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Helpers\n",
      "\n",
      "def write_log(msg, dataset):\n",
      "    with open('log.csv', 'a') as l:\n",
      "        csv.writer(l, delimiter=\",\").writerow([datetime.now().strftime('%Y-%m-%d %H:%M:%S')]+[msg]+[process]+[dataset])\n",
      "        \n",
      "def calc_dist(row, *args):\n",
      "    a =  np.asarray(ast.literal_eval(row['Rep']))\n",
      "    if a.size > 0:\n",
      "        d = a - args[0] # probe_rep\n",
      "        return np.dot(d, d) # distance\n",
      "    return -1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# OpenFace API\n",
      "\n",
      "fileDir = os.path.dirname(os.path.realpath('__file__'))\n",
      "modelDir = os.path.join(fileDir, '../../../openface', 'models')\n",
      "dlibModelDir = os.path.join(modelDir, 'dlib')\n",
      "openfaceModelDir = os.path.join(modelDir, 'openface')\n",
      "defaultImgs = '~/repos/openbr/data/lfw/Bill_Gates/{Bill_Gates_0001.jpg,Bill_Gates_0001.jpg}'\n",
      "defaultdlibFacePredictor = os.path.join(dlibModelDir, \"shape_predictor_68_face_landmarks.dat\")\n",
      "defaultnetworkModel = os.path.join(openfaceModelDir, 'nn4.small2.v1.t7')\n",
      "defaultImgDim = 96\n",
      "\n",
      "align = openface.AlignDlib(defaultdlibFacePredictor)\n",
      "net = openface.TorchNeuralNet(defaultnetworkModel, defaultImgDim)\n",
      "\n",
      "def getRep(imgPath, saveAligned, dataset):\n",
      "        img = cv2.imread(imgPath)\n",
      "\n",
      "        msg = \"\"\n",
      "        \n",
      "        if img is None:\n",
      "            write_log([imgPath, \"Unable to load image\"], dataset)\n",
      "            return np.array([])\n",
      "\n",
      "        rgbImg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
      "        \n",
      "        if img is None:\n",
      "            write_log([imgPath, \"Unable to convert image to rgb\"], dataset)\n",
      "            return np.array([])\n",
      "\n",
      "        # `img` is a numpy matrix containing the RGB pixels of the image.\n",
      "        bb = align.getLargestFaceBoundingBox(rgbImg)\n",
      "        \n",
      "        if bb is None:\n",
      "            write_log([imgPath, \"Unable to find a face\"], dataset)\n",
      "            return np.array([])\n",
      "        \n",
      "        alignedFace = align.align(defaultImgDim, rgbImg, bb,\n",
      "                                  landmarkIndices=openface.AlignDlib.OUTER_EYES_AND_NOSE)\n",
      "        \n",
      "        if alignedFace is None:\n",
      "            write_log([imgPath, \"Unable to align image\"], dataset)\n",
      "            return np.array([])\n",
      "\n",
      "        if saveAligned:\n",
      "            alignedFaceImg = Image.fromarray(alignedFace)\n",
      "            alignedFaceImg.save(\"alignedFace.jpg\")\n",
      "\n",
      "        rep = net.forward(alignedFace)\n",
      "        return rep"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Probe Single Image (Test)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imgPath = '../../../openbr/data/LFW/img/'\n",
      "\n",
      "img2 = os.path.join(imgPath, 'Bruce_Paltrow/Bruce_Paltrow_0001.jpg')\n",
      "img1 = os.path.join(imgPath, 'Gwyneth_Paltrow/Gwyneth_Paltrow_0003.jpg')\n",
      "\n",
      "rep = getRep(img2, True, 'none')\n",
      "rep2 = getRep(img1, True, 'none')\n",
      "\n",
      "d = rep - rep2\n",
      "dis = np.dot(d, d)\n",
      "\n",
      "print dis"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0127996565048\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Probe Templates"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Result output path\n",
      "result_path = \"meds_probing_results.csv\"\n",
      "# enrolled template peth\n",
      "template_path = \"../enroll/meds_enrolled_templates.csv\"\n",
      "# set true to continue enrollment from last index in csv file (template path)\n",
      "continue_from_last = False\n",
      "\n",
      "data_dir = '../../../openbr/data/MEDS/'\n",
      "image_dir = os.path.join(data_dir, 'img/')\n",
      "\n",
      "# probe data split\n",
      "test_ref_path = os.path.join(data_dir,'sigset/MEDS_frontal_query.xml')\n",
      "test_ref = minidom.parse(test_ref_path)\n",
      "test_sigs = test_ref.getElementsByTagName('presentation')\n",
      "test_length = len(test_sigs)\n",
      "\n",
      "print \"Loading template database...\"\n",
      "templates = pd.DataFrame.from_csv(template_path)\n",
      "\n",
      "print \"Comparing with enrolled templates...\"\n",
      "\n",
      "# columns for result csv\n",
      "columns = ['', 'Probe_Name', 'Probe_FileName', 'Best_Match', 'Best_Match_FileName', 'Distance', 'Correct']\n",
      "# index the probing should start from\n",
      "start_from_index = 0 \n",
      "\n",
      "# determine to continue from last or not\n",
      "if continue_from_last:\n",
      "    with open(result_path,\"r\") as f:\n",
      "        print \"Continuing...\"\n",
      "        reader = csv.reader(f,delimiter = \",\")\n",
      "        data = list(reader)\n",
      "        start_from_index = len(data) - 1\n",
      "        print \"Continuing from position {}\".format(start_from_index)\n",
      "else:\n",
      "    with open(result_path,\"wb\") as f:\n",
      "        print \"Starting from scratch\"\n",
      "        writer = csv.writer(f, delimiter=',')\n",
      "        writer.writerow(columns)\n",
      "        print \"Start from position {}\".format(start_from_index)\n",
      "\n",
      "\n",
      "# overall probe counter\n",
      "i = start_from_index\n",
      "# interval print counter\n",
      "y = 0\n",
      "\n",
      "print \"Probing {} images...\".format(test_length)\n",
      "print \"First entry: {}\".format(test_sigs[0].attributes['file-name'].value)\n",
      "\n",
      "with open(result_path, 'a') as f:\n",
      "    writer = csv.writer(f, delimiter=',')\n",
      "    \n",
      "    for s in test_sigs[start_from_index:]:        \n",
      "        name = s.attributes['file-name'].value.split('-')[0]\n",
      "        fname = image_dir + s.attributes['file-name'].value\n",
      "        #print fname\n",
      "\n",
      "        # Calculate probe representation\n",
      "        probe_rep = getRep(fname, False, data_dir)\n",
      "        if probe_rep.size == 0:\n",
      "            write_log(\"{} no representation generated\".format(fname))\n",
      "            continue\n",
      "        \n",
      "        # Calculate euclidean distance between templates and probe\n",
      "        templates['Distance'] = templates.apply(calc_dist, args = (probe_rep,), axis=1)\n",
      "        templates = templates[templates['Distance'] != -1]\n",
      "        # Sort by distance (where the lowest value is the best match)\n",
      "        best_match_data = templates.sort_values(by='Distance', ascending=True).iloc[0]\n",
      "        best_match_data.head() # Get predicted name and compare with probe name\n",
      "        probe_name = name\n",
      "        probe_filename = fname\n",
      "        best_match = best_match_data['Name']\n",
      "        best_match_filename = best_match_data['Template']\n",
      "        distance = best_match_data['Distance']\n",
      "        correct = int(probe_name == best_match)\n",
      "        row = [[i, probe_name, probe_filename, best_match, best_match_filename, distance, correct]]\n",
      "        writer.writerows(row)\n",
      "        \n",
      "        if y > 100:\n",
      "            print \"[{0:.2f}%] Probed 100 subjects\".format(i/test_length*100)\n",
      "            y = 0\n",
      "        \n",
      "        i = i + 1\n",
      "        y = y + 1\n",
      "        \n",
      "print \"Done\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading template database...\n",
        "Comparing with enrolled templates...\n",
        "Starting from scratch\n",
        "Start from position 0\n",
        "Probing 698 images...\n",
        "First entry: S001-01-t10_01.jpg\n",
        "[2016-06-16 23:09:41] ../../../openbr/data/MEDS/img/S118-02-t10_01.jpg no representation generated"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[14.47%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[2016-06-16 23:10:37] ../../../openbr/data/MEDS/img/S182-01-t10_01.jpg no representation generated"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[2016-06-16 23:10:40] ../../../openbr/data/MEDS/img/S185-03-t10_01.jpg no representation generated"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[2016-06-16 23:11:37] ../../../openbr/data/MEDS/img/S236-01-t10_01.jpg no representation generated"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[2016-06-16 23:12:03] ../../../openbr/data/MEDS/img/S259-01-t10_01.jpg no representation generated"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[28.94%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[43.41%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[57.88%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[72.35%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[2016-06-16 23:20:13] ../../../openbr/data/MEDS/img/S445-01-t10_01.jpg no representation generated"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[2016-06-16 23:20:13] ../../../openbr/data/MEDS/img/S446-02-t10_01.jpg no representation generated"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[2016-06-16 23:21:34] ../../../openbr/data/MEDS/img/S466-01-t10_01.jpg no representation generated"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[86.82%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[2016-06-16 23:22:05] ../../../openbr/data/MEDS/img/S474-01-t10_01.jpg no representation generated"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "CMC - Data Collection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_dir = '../../../openbr/data/' + 'LFW'\n",
      "image_dir = os.path.join(data_dir, 'img/')\n",
      "templates = pd.DataFrame.from_csv('../enroll/lfw_enrolled_templates.csv')\n",
      "\n",
      "# probe data split\n",
      "test_ref_path = os.path.join(data_dir,'sigset/test_image_restricted_query.xml')\n",
      "test_ref = minidom.parse(test_ref_path)\n",
      "test_sigs = test_ref.getElementsByTagName('presentation')\n",
      "\n",
      "y = 0\n",
      "\n",
      "ranks = 200\n",
      "rank_count = [0 for i in range(0,ranks)]\n",
      "\n",
      "print \"Template database size (training): {}\".format(len(templates))\n",
      "print \"Probe database size (test):\".format(len(test_sigs))\n",
      "j = 0\n",
      "for s in test_sigs:        \n",
      "    name = s.attributes['file-name'].value.split('/')[0]\n",
      "    fname = image_dir + s.attributes['file-name'].value\n",
      "\n",
      "    probe_rep = getRep(fname, False, data_dir)\n",
      "    \n",
      "    if probe_rep.size == 0:\n",
      "        write_log(\"{} no representation generated\".format(fname), 'lfw')\n",
      "        continue\n",
      "    \n",
      "    templates['Distance'] = templates.apply(calc_dist, args = (probe_rep,), axis=1)\n",
      "    templates = templates[templates['Distance'] != -1]\n",
      "    best_match_data = templates.sort_values(by='Distance', ascending=True)\n",
      "\n",
      "    for i in range(0,200):\n",
      "        rankings = best_match_data.head(i)\n",
      "        if len(rankings[rankings['Name'] == name]) > 0:\n",
      "            rank_count[i] = rank_count[i] + 1\n",
      "            \n",
      "    if y > 100:\n",
      "        print \"[{0:.2f}%] Probed 100 subjects\".format(j/len(test_sigs)*100)\n",
      "        y = 0\n",
      "        \n",
      "    y = y + 1\n",
      "    j = j + 1\n",
      "\n",
      "print 'done'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Template database size (training): 6000\n",
        "Probe database size (test):\n",
        "[1.68%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[3.37%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[5.05%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[6.73%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[8.42%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[10.10%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[11.78%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[13.47%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[15.15%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[16.83%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[18.52%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[20.20%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[21.88%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[23.57%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[25.25%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[26.93%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[28.62%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[30.30%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[31.98%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[33.67%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[35.35%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[37.03%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[38.72%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[40.40%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[42.08%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[43.77%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[45.45%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[47.13%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[48.82%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[50.50%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[52.18%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[53.87%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[55.55%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[57.23%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[58.92%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[60.60%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[62.28%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[63.97%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[65.65%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[67.33%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[69.02%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[70.70%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[72.38%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[74.07%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[75.75%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[77.43%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[79.12%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[80.80%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[82.48%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[84.17%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[85.85%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[87.53%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[89.22%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[90.90%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[92.58%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[94.27%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[95.95%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[97.63%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[99.32%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 127
    }
   ],
   "metadata": {}
  }
 ]
}