{
 "metadata": {
  "name": "",
  "signature": "sha256:2a00f5df81cf34e916d31316cc3074d51044f7a8e69f891dcabd4815efff6d15"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import openface\n",
      "import os\n",
      "import argparse\n",
      "import itertools\n",
      "import cv2\n",
      "import numpy as np\n",
      "from PIL import Image\n",
      "import pandas as pd\n",
      "import csv\n",
      "import ast\n",
      "from xml.dom import minidom\n",
      "from datetime import datetime\n",
      "\n",
      "%matplotlib inline\n",
      "\n",
      "process = \"probe\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Helpers\n",
      "\n",
      "def write_log(msg, dataset):\n",
      "    with open('log.csv', 'a') as l:\n",
      "        csv.writer(l, delimiter=\",\").writerow([datetime.now().strftime('%Y-%m-%d %H:%M:%S')]+[msg]+[process]+[dataset])\n",
      "        \n",
      "def calc_dist(row, *args):\n",
      "    a =  np.asarray(ast.literal_eval(row['Rep']))\n",
      "    if a.size > 0:\n",
      "        d = a - args[0] # probe_rep\n",
      "        return np.dot(d, d) # distance\n",
      "    return -1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# OpenFace API\n",
      "\n",
      "fileDir = os.path.dirname(os.path.realpath('__file__'))\n",
      "modelDir = os.path.join(fileDir, '../../../openface', 'models')\n",
      "dlibModelDir = os.path.join(modelDir, 'dlib')\n",
      "openfaceModelDir = os.path.join(modelDir, 'openface')\n",
      "defaultImgs = '~/repos/openbr/data/lfw/Bill_Gates/{Bill_Gates_0001.jpg,Bill_Gates_0001.jpg}'\n",
      "defaultdlibFacePredictor = os.path.join(dlibModelDir, \"shape_predictor_68_face_landmarks.dat\")\n",
      "defaultnetworkModel = os.path.join(openfaceModelDir, 'nn4.small2.v1.t7')\n",
      "defaultImgDim = 96\n",
      "\n",
      "align = openface.AlignDlib(defaultdlibFacePredictor)\n",
      "net = openface.TorchNeuralNet(defaultnetworkModel, defaultImgDim)\n",
      "\n",
      "def getRep(imgPath, saveAligned, dataset):\n",
      "        img = cv2.imread(imgPath)\n",
      "\n",
      "        msg = \"\"\n",
      "        \n",
      "        if img is None:\n",
      "            write_log([imgPath, \"Unable to load image\"], dataset)\n",
      "            return np.array([])\n",
      "\n",
      "        rgbImg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
      "        \n",
      "        if img is None:\n",
      "            write_log([imgPath, \"Unable to convert image to rgb\"], dataset)\n",
      "            return np.array([])\n",
      "\n",
      "        # `img` is a numpy matrix containing the RGB pixels of the image.\n",
      "        bb = align.getLargestFaceBoundingBox(rgbImg)\n",
      "        \n",
      "        if bb is None:\n",
      "            write_log([imgPath, \"Unable to find a face\"], dataset)\n",
      "            return np.array([])\n",
      "        \n",
      "        alignedFace = align.align(defaultImgDim, rgbImg, bb,\n",
      "                                  landmarkIndices=openface.AlignDlib.OUTER_EYES_AND_NOSE)\n",
      "        \n",
      "        if alignedFace is None:\n",
      "            write_log([imgPath, \"Unable to align image\"], dataset)\n",
      "            return np.array([])\n",
      "\n",
      "        if saveAligned:\n",
      "            alignedFaceImg = Image.fromarray(alignedFace)\n",
      "            alignedFaceImg.save(\"alignedFace.jpg\")\n",
      "\n",
      "        rep = net.forward(alignedFace)\n",
      "        return rep"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Probe Single Image (Test)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imgPath = '../../../openbr/data/LFW/img/'\n",
      "\n",
      "img2 = os.path.join(imgPath, 'Bruce_Paltrow/Bruce_Paltrow_0001.jpg')\n",
      "img1 = os.path.join(imgPath, 'Gwyneth_Paltrow/Gwyneth_Paltrow_0003.jpg')\n",
      "\n",
      "rep = getRep(img2, True, 'none')\n",
      "rep2 = getRep(img1, True, 'none')\n",
      "\n",
      "d = rep - rep2\n",
      "dis = np.dot(d, d)\n",
      "\n",
      "print dis"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0127996565048\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Probe Templates"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Result output path\n",
      "result_path = \"meds_probing_results.csv\"\n",
      "# enrolled template peth\n",
      "template_path = \"../enroll/meds_enrolled_templates.csv\"\n",
      "# set true to continue enrollment from last index in csv file (template path)\n",
      "continue_from_last = False\n",
      "\n",
      "data_dir = '../../../openbr/data/MEDS/'\n",
      "image_dir = os.path.join(data_dir, 'img/')\n",
      "\n",
      "# probe data split\n",
      "test_ref_path = os.path.join(data_dir,'sigset/MEDS_frontal_query.xml')\n",
      "test_ref = minidom.parse(test_ref_path)\n",
      "test_sigs = test_ref.getElementsByTagName('presentation')\n",
      "test_length = len(test_sigs)\n",
      "\n",
      "print \"Loading template database...\"\n",
      "templates = pd.DataFrame.from_csv(template_path)\n",
      "\n",
      "print \"Comparing with enrolled templates...\"\n",
      "\n",
      "# columns for result csv\n",
      "columns = ['', 'Probe_Name', 'Probe_FileName', 'Best_Match', 'Best_Match_FileName', 'Distance', 'Correct']\n",
      "# index the probing should start from\n",
      "start_from_index = 0 \n",
      "\n",
      "# determine to continue from last or not\n",
      "if continue_from_last:\n",
      "    with open(result_path,\"r\") as f:\n",
      "        print \"Continuing...\"\n",
      "        reader = csv.reader(f,delimiter = \",\")\n",
      "        data = list(reader)\n",
      "        start_from_index = len(data) - 1\n",
      "        print \"Continuing from position {}\".format(start_from_index)\n",
      "else:\n",
      "    with open(result_path,\"wb\") as f:\n",
      "        print \"Starting from scratch\"\n",
      "        writer = csv.writer(f, delimiter=',')\n",
      "        writer.writerow(columns)\n",
      "        print \"Start from position {}\".format(start_from_index)\n",
      "\n",
      "\n",
      "# overall probe counter\n",
      "i = start_from_index\n",
      "# interval print counter\n",
      "y = 0\n",
      "\n",
      "print \"Probing {} images...\".format(test_length)\n",
      "print \"First entry: {}\".format(test_sigs[0].attributes['file-name'].value)\n",
      "\n",
      "with open(result_path, 'a') as f:\n",
      "    writer = csv.writer(f, delimiter=',')\n",
      "    \n",
      "    for s in test_sigs[start_from_index:]:        \n",
      "        name = s.attributes['file-name'].value.split('-')[0]\n",
      "        fname = image_dir + s.attributes['file-name'].value\n",
      "        #print fname\n",
      "\n",
      "        # Calculate probe representation\n",
      "        probe_rep = getRep(fname, False, data_dir)\n",
      "        if probe_rep.size == 0:\n",
      "            write_log(\"{} no representation generated\".format(fname))\n",
      "            continue\n",
      "        \n",
      "        # Calculate euclidean distance between templates and probe\n",
      "        templates['Distance'] = templates.apply(calc_dist, args = (probe_rep,), axis=1)\n",
      "        templates = templates[templates['Distance'] != -1]\n",
      "        # Sort by distance (where the lowest value is the best match)\n",
      "        best_match_data = templates.sort_values(by='Distance', ascending=True).iloc[0]\n",
      "        best_match_data.head() # Get predicted name and compare with probe name\n",
      "        probe_name = name\n",
      "        probe_filename = fname\n",
      "        best_match = best_match_data['Name']\n",
      "        best_match_filename = best_match_data['Template']\n",
      "        distance = best_match_data['Distance']\n",
      "        correct = int(probe_name == best_match)\n",
      "        row = [[i, probe_name, probe_filename, best_match, best_match_filename, distance, correct]]\n",
      "        writer.writerows(row)\n",
      "        \n",
      "        if y > 100:\n",
      "            print \"[{0:.2f}%] Probed 100 subjects\".format(i/test_length*100)\n",
      "            y = 0\n",
      "        \n",
      "        i = i + 1\n",
      "        y = y + 1\n",
      "        \n",
      "print \"Done\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading template database...\n",
        "Comparing with enrolled templates...\n",
        "Starting from scratch\n",
        "Start from position 0\n",
        "Probing 698 images...\n",
        "First entry: S001-01-t10_01.jpg\n",
        "[2016-06-16 23:09:41] ../../../openbr/data/MEDS/img/S118-02-t10_01.jpg no representation generated"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[14.47%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[2016-06-16 23:10:37] ../../../openbr/data/MEDS/img/S182-01-t10_01.jpg no representation generated"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[2016-06-16 23:10:40] ../../../openbr/data/MEDS/img/S185-03-t10_01.jpg no representation generated"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[2016-06-16 23:11:37] ../../../openbr/data/MEDS/img/S236-01-t10_01.jpg no representation generated"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[2016-06-16 23:12:03] ../../../openbr/data/MEDS/img/S259-01-t10_01.jpg no representation generated"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[28.94%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[43.41%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[57.88%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[72.35%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[2016-06-16 23:20:13] ../../../openbr/data/MEDS/img/S445-01-t10_01.jpg no representation generated"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[2016-06-16 23:20:13] ../../../openbr/data/MEDS/img/S446-02-t10_01.jpg no representation generated"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[2016-06-16 23:21:34] ../../../openbr/data/MEDS/img/S466-01-t10_01.jpg no representation generated"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[86.82%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[2016-06-16 23:22:05] ../../../openbr/data/MEDS/img/S474-01-t10_01.jpg no representation generated"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_ref_path"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 126,
       "text": [
        "'../../../openbr/data/LFW/sigset/test_image_restricted_query.xml'"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CMC\n",
      "data_dir = '../../../openbr/data/' + 'LFW'\n",
      "image_dir = os.path.join(data_dir, 'img/')\n",
      "templates = pd.DataFrame.from_csv('../enroll/lfw_enrolled_templates.csv')\n",
      "\n",
      "# probe data split\n",
      "test_ref_path = os.path.join(data_dir,'sigset/test_image_restricted_query.xml')\n",
      "test_ref = minidom.parse(test_ref_path)\n",
      "test_sigs = test_ref.getElementsByTagName('presentation')\n",
      "\n",
      "y = 0\n",
      "\n",
      "ranks = 200\n",
      "rank_count = [0 for i in range(0,ranks)]\n",
      "\n",
      "print \"Template database size (training): {}\".format(len(templates))\n",
      "print \"Probe database size (test):\".format(len(test_sigs))\n",
      "j = 0\n",
      "for s in test_sigs:        \n",
      "    name = s.attributes['file-name'].value.split('/')[0]\n",
      "    fname = image_dir + s.attributes['file-name'].value\n",
      "\n",
      "    probe_rep = getRep(fname, False, data_dir)\n",
      "    \n",
      "    if probe_rep.size == 0:\n",
      "        write_log(\"{} no representation generated\".format(fname), 'lfw')\n",
      "        continue\n",
      "    \n",
      "    templates['Distance'] = templates.apply(calc_dist, args = (probe_rep,), axis=1)\n",
      "    templates = templates[templates['Distance'] != -1]\n",
      "    best_match_data = templates.sort_values(by='Distance', ascending=True)\n",
      "\n",
      "    for i in range(0,200):\n",
      "        rankings = best_match_data.head(i)\n",
      "        if len(rankings[rankings['Name'] == name]) > 0:\n",
      "            rank_count[i] = rank_count[i] + 1\n",
      "            \n",
      "    if y > 100:\n",
      "        print \"[{0:.2f}%] Probed 100 subjects\".format(j/len(test_sigs)*100)\n",
      "        y = 0\n",
      "        \n",
      "    y = y + 1\n",
      "    j = j + 1\n",
      "\n",
      "print 'done'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Template database size (training): 6000\n",
        "Probe database size (test):\n",
        "[1.68%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[3.37%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[5.05%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[6.73%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[8.42%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[10.10%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[11.78%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[13.47%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[15.15%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[16.83%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[18.52%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[20.20%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[21.88%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[23.57%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[25.25%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[26.93%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[28.62%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[30.30%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[31.98%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[33.67%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[35.35%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[37.03%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[38.72%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[40.40%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[42.08%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[43.77%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[45.45%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[47.13%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[48.82%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[50.50%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[52.18%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[53.87%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[55.55%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[57.23%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[58.92%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[60.60%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[62.28%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[63.97%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[65.65%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[67.33%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[69.02%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[70.70%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[72.38%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[74.07%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[75.75%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[77.43%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[79.12%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[80.80%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[82.48%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[84.17%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[85.85%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[87.53%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[89.22%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[90.90%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[92.58%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[94.27%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[95.95%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[97.63%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[99.32%] Probed 100 subjects"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cmc_meds_ranks = [rc/len(test_sigs) for rc in rank_count]\n",
      "cmc_ranks = range(0,ranks)\n",
      "\n",
      "cmc = pd.DataFrame({'x': cmc_ranks, 'OpenFace (Similarity) LFW': cmc_meds_ranks})\n",
      "cmc.plot(x='x', logx=True, ylim=(0,1))\n",
      "\n",
      "cmc.to_csv('cmc_lfw_dataframe.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEUCAYAAADk2bcWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7ffab93c0dd0>"
       ]
      }
     ],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}