{
 "metadata": {
  "name": "",
  "signature": "sha256:04e9f18a889d1c83d756af6b7d7c852f00e5f81a577224d253083c652d526ad6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Imports\n",
      "from __future__ import division\n",
      "import openface\n",
      "import os\n",
      "import argparse\n",
      "import itertools\n",
      "import cv2\n",
      "import numpy as np\n",
      "from PIL import Image\n",
      "import pandas as pd\n",
      "import csv\n",
      "import ast\n",
      "from xml.dom import minidom\n",
      "from datetime import datetime\n",
      "\n",
      "process = \"enroll\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Helpers\n",
      "\n",
      "def write_log(msg, dataset):\n",
      "    with open('log.csv', 'a') as l:\n",
      "        csv.writer(l, delimiter=\",\").writerow([datetime.now().strftime('%Y-%m-%d %H:%M:%S')]+msg+[process]+[dataset])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# OpenFace API\n",
      "\n",
      "fileDir = os.path.dirname(os.path.realpath('__file__'))\n",
      "modelDir = os.path.join(fileDir, '../../../openface', 'models')\n",
      "dlibModelDir = os.path.join(modelDir, 'dlib')\n",
      "openfaceModelDir = os.path.join(modelDir, 'openface')\n",
      "defaultImgs = '~/repos/openbr/data/lfw/Bill_Gates/{Bill_Gates_0001.jpg,Bill_Gates_0001.jpg}'\n",
      "defaultdlibFacePredictor = os.path.join(dlibModelDir, \"shape_predictor_68_face_landmarks.dat\")\n",
      "defaultnetworkModel = os.path.join(openfaceModelDir, 'nn4.small2.v1.t7')\n",
      "defaultImgDim = 96\n",
      "\n",
      "align = openface.AlignDlib(defaultdlibFacePredictor)\n",
      "net = openface.TorchNeuralNet(defaultnetworkModel, defaultImgDim)\n",
      "\n",
      "def getRep(imgPath, saveAligned, dataset):\n",
      "        img = cv2.imread(imgPath)\n",
      "\n",
      "        msg = \"\"\n",
      "        \n",
      "        if img is None:\n",
      "            write_log([imgPath, \"Unable to load image\"], dataset)\n",
      "            return np.array([])\n",
      "\n",
      "        rgbImg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
      "        \n",
      "        if img is None:\n",
      "            write_log([imgPath, \"Unable to convert image to rgb\"], dataset)\n",
      "            return np.array([])\n",
      "\n",
      "        # `img` is a numpy matrix containing the RGB pixels of the image.\n",
      "        bb = align.getLargestFaceBoundingBox(rgbImg)\n",
      "        \n",
      "        if bb is None:\n",
      "            write_log([imgPath, \"Unable to find a face\"], dataset)\n",
      "            return np.array([])\n",
      "        \n",
      "        alignedFace = align.align(defaultImgDim, rgbImg, bb,\n",
      "                                  landmarkIndices=openface.AlignDlib.OUTER_EYES_AND_NOSE)\n",
      "        \n",
      "        if alignedFace is None:\n",
      "            write_log([imgPath, \"Unable to align image\"], dataset)\n",
      "            return np.array([])\n",
      "\n",
      "        if saveAligned:\n",
      "            alignedFaceImg = Image.fromarray(alignedFace)\n",
      "            alignedFaceImg.save(\"alignedFace.jpg\")\n",
      "\n",
      "        rep = net.forward(alignedFace)\n",
      "        return rep"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Enroll Templates"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# enrolled template output path\n",
      "templates_path = \"meds_enrolled_templates.csv\"\n",
      "# set true to continue enrollment from last index in csv file (template path)\n",
      "continue_from_last = False \n",
      "\n",
      "data_dir = '../../../openbr/data/MEDS/'\n",
      "image_dir = os.path.join(data_dir, 'img/')\n",
      "\n",
      "# Training data split\n",
      "training_ref_path = os.path.join(data_dir,'sigset/MEDS_frontal_target.xml')\n",
      "training_ref = minidom.parse(training_ref_path)\n",
      "training_sigs = training_ref.getElementsByTagName('presentation')\n",
      "training_length = len(training_sigs)\n",
      "\n",
      "# columns for templates_db\n",
      "columns = ['', 'Name', 'Template', 'Rep']\n",
      "\n",
      "# index the enrollment should start from\n",
      "start_from_index = 0 \n",
      "\n",
      "# determine to continue from last or not\n",
      "if continue_from_last:\n",
      "    with open(templates_path,\"r\") as f:\n",
      "        reader = csv.reader(f,delimiter = \",\")\n",
      "        data = list(reader)\n",
      "        start_from_index = len(data) - 1\n",
      "        print \"Continuing from position {}\".format(start_from_index)\n",
      "else:\n",
      "    with open(templates_path,\"wb\") as f:\n",
      "        writer = csv.writer(f, delimiter=',')\n",
      "        writer.writerow(columns)\n",
      "        print \"Start from position {}\".format(start_from_index)\n",
      "        \n",
      "# overall training counter\n",
      "i = start_from_index\n",
      "# interval print counter\n",
      "y = 0 \n",
      "        \n",
      "print \"Enrolling {} images...\".format(training_length)\n",
      "print \"First entry: {}\".format(training_sigs[0].attributes['file-name'].value)\n",
      "\n",
      "with open(templates_path, 'a') as f:\n",
      "    writer = csv.writer(f, delimiter=',')\n",
      "\n",
      "    for s in training_sigs[start_from_index:]:\n",
      "        name = s.attributes['file-name'].value.split('-')[0]\n",
      "        fname = image_dir + s.attributes['file-name'].value\n",
      "        \n",
      "        #print \"[{}%] Enrolling {}\".format(i/limit * 100, fname)\n",
      "        \n",
      "        #rpath = os.path.join(data_dir,fname)\n",
      "        \n",
      "        row = [[i, name, fname, getRep(fname, False, data_dir).tolist()]]\n",
      "        writer.writerows(row)\n",
      "        \n",
      "        i = i + 1\n",
      "        y = y + 1\n",
      "        \n",
      "        if y > 100:\n",
      "            print \"[{0:.2f}%] Enrolled 100 images\".format(i/training_length * 100)\n",
      "            y = 0\n",
      "            \n",
      "    print \"Done\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Start from position 0\n",
        "Enrolling 518 images...\n",
        "First entry: S001-04-t10_01.jpg\n",
        "[19.50%] Enrolled 100 images"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[39.00%] Enrolled 100 images"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[58.49%] Enrolled 100 images"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[77.99%] Enrolled 100 images"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[97.49%] Enrolled 100 images"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}